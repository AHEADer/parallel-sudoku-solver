{"name":"Parallel-sudoku-solver","tagline":"Parallelized Sudoku Solver on the GPU","body":"# Parallelized Sudoku Solver on the GPU\r\n###### Victor Duan and Michael Teng\r\n###### CS 179: GPU Programming Caltech Spring 2015\r\n\r\n### Summary\r\n\r\nWe implemented a parallelized CUDA program that can efficiently solve a Sudoku puzzle using a\r\nbacktracking algorithm.\r\n\r\n### Background\r\n\r\n##### Introduction to Sudoku\r\n\r\nSudoku is a popular puzzle game usually played on a 9x9 board of numbers between 1 and 9.\r\n\r\n![alt text](https://github.com/vduan/cs179sudoku/blob/master/res/img/ex_sudoku_board.png?raw=true \"Example Sudoku Board\")\r\n\r\nThe goal of the game is to fill the board with numbers. However, each row can only contain one of\r\neach of the numbers between 1 and 9. Similarly, each column and 3x3 sub-board can only contain one\r\nof each of the numbers between 1 and 9. This makes for an engaging and challenging puzzle game.\r\n\r\nA standard Sudoku puzzle may have about 50-60 empty spaces to solve for. A brute force algorithm\r\nwould have an incredibly large search space to wade through. In fact, the task of solving a Sudoku\r\npuzzle is NP-complete.\r\n\r\n##### Solving Algorithm\r\n\r\nA common algorithm to solve Sudoku boards is called backtracking. This algorithm is essentially a\r\ndepth first search in the tree of all possible guesses in the empty space of the Sudoku board. The\r\nalgorithm finds the first open space, and tries the number 1 there. If that board is valid, it will\r\ncontinue trying values in the other open spaces. If the board is ever invalid, backtrack by undoing\r\nthe most recent guess and try another value there. If all values have been tried, backtrack again.\r\nIf the board is valid and there are no more empty spaces, the board has been solved! If the\r\nbacktracking goes back to the first empty space and there are no more possible values, we have tried\r\nevery possible combination of numbers on the board and there is no solution. We can illustrate this\r\nmore clearly with the pseudocode of the algorithm here:\r\n\r\n```\r\nrecursive_backtrack():\r\n    if board is valid:\r\n        index = index of first empty spot in board\r\n        for value = 1 to 9:\r\n            set board[index] = value\r\n            if recursive_backtrack():\r\n                return true;  // solved!\r\n            set board[index] = 0\r\n    // if we tried all values, or the board is invalid, backtrack\r\n    return false;\r\n```\r\n\r\n##### Parallelization Challenges\r\n\r\nAt first glance, this algorithm, and indeed depth first search in general, does not appear to be\r\nvery parallelizable. This is because the algorithm depends on a stack. In the recursive case, the\r\nstack is implicit in the function call stack. Stacks are hard to parallelize because threads cannot\r\nall work off of the same stack and productively move forward in the algorithm together without\r\ncausing very high contention for access to the stack.\r\n\r\n##### Alternative Solutions\r\n###### Simulated Annealing\r\n\r\nSimulated annealing is a heuristic to solve optimization problems using probabilistic methods. The\r\nbasic idea is to begin by filling the Sudoku board with the numbers. These numbers need not be in\r\nthe correct place, but there should be exactly nine of each number from 1-9 on the board.\r\nAdditionally, each of the 3x3 sub-boards should have every number from 1-9. The algorithm then\r\nproceeds as follows:\r\n\r\n1. Randomly choose one of the sub-boxes and swap two of the non-fixed numbers.\r\n2. If the board is \"better\", leave it as is and continue.\r\n3. If the board is not \"better\", probabilistically change it back to the original board.\r\n\r\nNow, what do we mean by better? We can score the boards so that the algorithm has an optimization in\r\nmind. One potential scoring system is to score a board by adding -1 for each unique number in each\r\nrow and column. Thus, if a row has 9 unique values, it contributes -9 to the score. The board is\r\nthen solved if the score is -162, which corresponds to 9 unique values in every row and column and\r\neach sub-box has 9 unique values from the start.\r\n\r\nThis algorithm typically needs to be run for thousands of generations to find a solution. However,\r\nwe can see that many of these swaps may not really interact with each other (if they are in\r\ndifferent sub-boards). Additionally, there is not really an order that needs to be preserved. Thus,\r\nthis looks like a parallelizable approach to solving Sudoku puzzles that is ideal for the GPU.\r\n\r\n###### Dancing Links\r\n\r\nThe Dancing Links algorithm was devloped by Donald Knuth to solve the exact cover problem. Without\r\ngetting into the details, the exact cover problem takes a matrix of 0's and 1s and searches for a\r\nset of rows such that in those rows, each column contains exactly one non-zero value. The problem is\r\nthen to express Sudoku as an exact cover problem. We can see that Sudoku can be described as a set\r\nof constraints for each location of the board:\r\n\r\n1. Each space may only contain a single value.\r\n2. Each row may only contain each number one time.\r\n3. Each column may only contain each number one time.\r\n4. Each sub-board may only contain each number one time.\r\n\r\nWe can express these constraints in a single row of length N * N * 4 where N = 9 for a standard\r\nSudoku board and 4 is for the 4 constraints. We must also have a row for potential space and number,\r\nwhich is N * N * N rows. This gives us a matrix of size N^3 x 4N^2. The initial state of the board\r\ncan be expressed by selecting which rows are in the exact cover. The output of the Dancing Links\r\nalgorithm will give us a subset of rows where each constraint is filled exactly once. Each row\r\nrepresents a space-number pairing, so the exact cover will be a solution to the Sudoku puzzle.\r\n\r\nHowever, the Dancing Links algorithm does not appear to be a very parallelizable solution either. At\r\nits core, it is similar to the depth first search solution and will face similar parallelization\r\nchallenges.\r\n\r\n###### Parallelization over different branches of the depth first search\r\n\r\nFinally, we can modify the depth first search approach so that threads can function independently\r\nwithout all reading from the same stack. Breadth first search is easy to parallelize, so we can\r\nbegin by finding all possible valid boards that fill the first, say, 20 empty spaces of the given\r\npuzzle. This may give us something like thousands of possible boards. These boards may then be\r\npassed to another kernel, where each thread then applies the backtracking algorithm to it's own\r\nboard. If any thread finds a solution, all threads stop, and that solution is passed back to the\r\ncpu.\r\n\r\nWe can see that both of these steps are much easier to parallelize than the original depth first\r\nsearch solution. In the end, this is the primary approach we chose to focus on.\r\n\r\n### Approach: Parallel Backtracking\r\n\r\n##### Algorithm\r\n\r\nThe parallel approach to backtracking can be broken down into two main steps:\r\n\r\n1. Breadth first search from the beginning board to find all possible boards with the first X empty\r\nspaces filled. This will return Y possible starting boards for the next step of the algorithm.\r\n\r\n2. Attempt to solve each of these Y boards separately in different threads on the GPU. If a solution\r\nis found, terminate the program and return the solution.\r\n\r\nThe speedup of this approach is in the parallelization of part 2. This allows us to search through\r\nthe depth first search approach in parallel, which allows for great speedup.\r\n\r\nWe can do each of these steps in separate kernels.\r\n\r\n##### Board Generation Kernel\r\n\r\nThis kernel will expect the following things as input:\r\n\r\n- the previous frontier of boards from which we will be searching\r\n- a pointer to where the next layer of boards will be stored\r\n- total number of boards in the previous frontier\r\n- a pointer to where the indices of the empty spaces in the next layer of boards will be stored\r\n- a pointer to where the number of empty spaces in each board is stored\r\n\r\nThe kernel will spawn threads where each one generates the children of the board. This can be done \r\nwithout knowing the actual graph, because the children board of each input is simply the possible \r\nboards given the first empty space. For example, if there is an empty and the numbers, 1,2,3,6,9 \r\nall work, this thread will add 5 new boards to the new boards array. For difficult sudokus, worst case\r\nthe board starts to grow by a factor of 9 per level. Of course, in practice, this is never the case, \r\nbut given this, we have set a heuristic on how far the BFS will go. For us, we use the 20th level, as\r\nthis will result in about ~50 thousand, which is a nice number to send to DFS, given that there is\r\n64k registers on the average single gpu (Kepler). \r\n\r\n##### Backtracking Kernel\r\n\r\nThis kernel will expect the following things as input:\r\n\r\n- all the boards to search through\r\n- number of boards to search through\r\n- location of the empty spaces\r\n- number of empty spaces\r\n\r\nThe kernel will then spawn threads that each individually handle one board at a time. It will do the\r\nclassic backtracking algorithm as described earlier.\r\n\r\nIt is important to note that recursion has some issues on GPU programming. While it is supported for\r\ncompute capability >=2.0, we found that implementing it resulted in strange behavior, even for a\r\nsingle thread. The same code may be run on the cpu and run just fine. Thus, we switched from using\r\nthe implicit stack of recursive depth first search (function call stack) to an explicit stack of\r\ndepth first search, where we try values at each empty space and backtrack. This is why we also\r\ninclude the location of the empty spaces and the number of empty spaces total.\r\n\r\nWe also use a global finished flag so that when a solution is found, all threads are notified and\r\nthe kernel can terminate.\r\n\r\nThis kernel allows us to work on these boards at (# of threads) the speed because that is how many\r\nboards we can process at once.\r\n\r\n\r\n### Results\r\n\r\nIn general, we find that using our parallelized backtracking algorithm results in speed ups on  the\r\norder of 10. For our two sample boards, we found that the cpu backtracing, which is entirely\r\nsequential results in ~4 milliseconds and ~3 seconds for the easy and hard boards, respectively.  On\r\nthe gpu, we find that kernel calls take ~1 millisecond and ~800 milliseconds for the easy and hard\r\nboards, respectively. We also ran analyses on the backtracking algorithm for a single board to the\r\nkernel in order to get a better benchmark for how much BFS speedup is. The kernels for a  single\r\nboard, and thus single thread DFS is about 30 times slower, than when we parallelize on the 20th\r\nlevel of the search space.\r\n\r\n### References\r\n\r\n1. For insights on applying Knuth's Dancing Links algorithm to solving Sudoku puzzles:\r\nhttps://www.ocf.berkeley.edu/~jchu/publicportal/sudoku/sudoku.paper.html\r\n\r\n2. For insights on the simulated annealing approach to solving Sudoku puzzles: \"Sudoku Using\r\nParallel Simulated Annealing\" by Zahra Karimi-Dehkordi, Kamran Zamanifar, Ahmad Baraani-Dastjerdi,\r\nNasser Ghasem-Aghaee. http://link.springer.com/chapter/10.1007/978-3-642-13498-2_60#\r\n\r\n\r\n\r\n\r\n### How to run parallel Sudoku solver\r\n\r\n1. To compile the code, navigate to the src/ directory and run make. The executable will appear in\r\nthe bin/ directory.\r\n\r\n2. To run the solver, run the executable with arguments for threads per block, max number of blocks,\r\nand filename of the puzzle. We have supplied some sample boards in the res/sample_inputs/ directory.\r\nYou can, of course, create your own boards to test. The numbers in the file should be 0 for empty,\r\nand between 1 and 9 for filled spaces.\r\n\r\n```\r\ncd SUDOKU_DIR/src/\r\nmake\r\nSUDOKU_DIR/bin/CudaSudoku 512 256 SUDOKU_DIR/res/sample_inputs/hard_1.txt\r\n```","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}